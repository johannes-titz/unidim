---
title: "Analysis for Titz: The Relationship between Phi and H"
author: "Johannes Titz"
date: "04/27/2023"
#original date: "2/23/2022"
output:
  github_document:
    toc: true
---
<!-- @myself: the paper is in 2022/fa_paper-->
This analysis accompanies the paper: Titz, J. The Relationship Between the Phi Coefficient and the Unidimensionality Index H: Improving Psychological Scaling From the Ground Up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, cache = F,
                      options(width = 82))
```

# Part I: Theory

## Prepare

I use librarian to manage dependencies, so please install it if you do not have it yet (uncomment the first line).

```{r prepare}
# install.packages("librarian")
library(librarian)
shelf(partitions, pbapply, tidyverse, psych, johannes-titz/zysno, xtable, 
      Matrix, plot.matrix, simpleCache)
setCacheDir("cache")
# use multiple cores
cores <- round(parallel::detectCores() * 0.8)
# create vectors from phi matrix
vec_from_tbl <- function(a, b, c, d) {
  mtrx <- matrix(c(a, b, c, d), ncol = 2)
  v1 <- rep(c(0, 1), colSums(mtrx))
  v2 <- rep(c(0, 1), rowSums(mtrx))
  cbind(v1, v2)
}

# create vectors from phi matrix
vectors_from_crosstable <- function(freq_ct, n_cat = sqrt(length(freq_ct))) {
  m <- matrix(freq_ct, ncol = n_cat)
  #graph <- Kmisc::melt_(m)
  graph <- reshape2::melt(m)
  v1 <- rep(graph[,1], graph[,3])
  v2 <- rep(graph[,2], graph[,3])
  m2 <- cbind(v1, v2)
  m2
}
# for trichotomous/polytomous
stats <- function(freq_ct) {
  if (sum(freq_ct != 0) == 1) return(cbind(H = NA, r = NA))
  m <- vectors_from_crosstable(freq_ct)
  if (any(var(m) == 0)) return(cbind(H = NA, r = NA))
  # avoid calculating H
  if (cor(m)[1,2] < 0) return(cbind(H = NA, r = NA))
  H <- suppressWarnings(mokken::coefH(m, nice.output = F, results = F))
  cbind(H = as.numeric(H$H), phi = cor(m)[1,2])
}
```

## dichotomous

### Generate Data

```{r generate dich, cache = F}
n <- 200
# all combos, even the ones where phi is NA
grid <- as.matrix(t(compositions(n = n, m = 4)))
colnames(grid) <- paste0("Var", 1:4)
# rowwise does not work with the following code, I do not know why
# multiple cores seem to give no advantage, so is not used (argument cl)
# we cache this manually as it takes some time
grid <- xfun::cache_rds({
  grid <- as_tibble(grid) %>%
    rowwise() %>%
    mutate(errors = Var3,
           expected_errors = (Var1 + Var3) * (Var3 + Var4) / (Var1+ Var2+ Var3+ Var4),
           h = 1 - errors / expected_errors)
  phi <- pbapply(grid[, 1:4], 1, function(x) phi(x, digits = 4))
  cbind(grid, phi)
}, file = "sim1", rerun = F)
grid <- as_tibble(grid)
```

```{r filter dich}
grid_unidim <-  grid %>%
  filter(Var3 == 0) # only unidimensional
grid_row <- grid %>%
  filter(phi >= 0, Var2 >= Var3) # error cell is b
```

### Plot

```{r phihs}
p <- ggplot(grid_row, aes(phi, h)) + 
  #geom_point(alpha = 0.05) +
  geom_hex(bins = 100, show.legend = FALSE) + 
  theme_classic() +
  scale_x_continuous("Phi", breaks = seq(0, 1, 0.1)) + 
  scale_y_continuous("H", breaks = seq(0, 1, 0.1) ) + 
  coord_fixed()
p
pdf("plots/phiH.pdf", width = 5, height = 5)
p
dev.off()
```

## trichotomous

Note that the code is not very efficient and can likely be improved considerably.

### Generate Data

The following two chunks are highly resource-intensive, demanding substantial RAM and time to recreate or load due to the objects' uncompressed size of approximately 20 GB. Consequently, they are not executed by default. To recreate or load these chunks, adjust the chunk settings as needed. Ensure you have sufficient RAM available (e.g., on a server) before running them. If you prefer not to recreate the data, you can proceed to the subsequent chunk, which loads the final relevant statistics from the cache (default).

```{r generate tri, eval=FALSE, cache=FALSE}
n <- 30
# all combos, even the ones where phi is NA
simpleCache("grid_poly", as.data.frame(as.matrix(compositions(n = n, m = 9))))
```

```{r generate 2 tri, cache = F, eval=FALSE}
simpleCache("poly", pbmcapply::pbmclapply(grid_poly, stats, mc.cores = 2))
poly <- data.frame(matrix(unlist(poly2), ncol = 2, byrow = T))
names(poly) <- c("H", "phi")
```

```{r filter tri}
simpleCache("grid_row_tri", poly[poly$phi >= 0, ])
```

### Plot

```{r phihs tri, cache = T}
p <- ggplot(grid_row_tri, aes(phi, H)) +
  #geom_point(alpha = 0.05) +
  geom_hex(bins = 100, show.legend = FALSE) +
  theme_classic() +
  scale_x_continuous("Phi", breaks = seq(0, 1, 0.1)) +
  scale_y_continuous("H", breaks = seq(0, 1, 0.1) ) +
  coord_fixed()
p
pdf("plots/phiHPoly.pdf", width = 5, height = 5)
p
dev.off()
```

## FA model

It is not hard to create unidimensional model that results in a perfect bifactor solution with factor analysis (for Pearson Correlation):

```{r fa}
m1 <- vec_from_tbl(10, 80, 0, 10)
m2 <- vec_from_tbl(11, 78, 0, 11)
m3 <- vec_from_tbl(15, 70, 0, 15)

d <- cbind(m1, m2, m3[, -2])
# check that it is really unidimensional
zysnotize(d)

ncol <- ncol(d)
colnames(d) <- paste("Item", seq(ncol(d)))
f1 <- factanal(d, 1)
f2 <- factanal(d, 2)

f1$loadings
f2$loadings
print(xtable::xtable(cbind(f1$loadings, f2$loadings), label = "tab:fa1b", 
                     caption = "Cross tables of five unidimensional items"),
      file = "tables/fa1b.tex", booktabs = TRUE)

combs <- Map(function(x, y) table(d[, x], d[, y]),
             rep(1:ncol, each = ncol), rep(1:ncol, ncol))
lower <- seq(1, 21, 5)
upper <- seq(5, 25, 5)
res <- Map(function(x, y) Reduce(cbind, combs[x:y]),
    lower, upper)
res2 <- Reduce(rbind, res)
colnames(res2) <- paste0("$", rep(1:5, each = 2), "_", c(0, 1), "$")
rownames(res2) <- paste0("$", rep(1:5, each = 2), "_", c(0, 1), "$")

res2
print(xtable::xtable(res2, label = "tab:fa1",
                     caption = "Example of factor analysis for five unidimensional items"),
      booktabs = TRUE,
      file = "tables/fa1.tex",
      sanitize.text.function = function(x) {x})
```

# Part II: Empirical Example

Load data

```{r emp prepare}
dorig <- read.csv2("data.csv")
d <- dorig %>%
  select(id, item_nmbr, correctness) %>%
  pivot_wider(names_from = item_nmbr, values_from = correctness)
```
```

Find order, calculate score, show df

```{r emp order}
o <- order(colMeans(d[,-1]), decreasing = TRUE)
d <- d[, c(1, o+1)]
d$score <- rowSums(d[, -1])
df <- as.data.frame(d)
df[order(df$score), ]
```

### Violations

```{r emp viol}
is_monotonic <- function(x) {
  all(diff(as.numeric(x)) <= 0)
}

df$monotonic <- apply(df[, 2:6], 1, is_monotonic)
dg <- df[df$monotonic == FALSE, ]

dh <- dg[order(dg$score), ]
dh
print(
      xtable::xtable(dh[, 2:7], caption = "Participant answers that violate unidimensionality", 
                     label = "tab:viol", digits = 0),
      booktabs = TRUE,
      file = "tables/viol.tex"
)
```

### unidim analysis

```{r unidim h}
lv <- loevenize(as.matrix(d[, 2:6]))
lv
1-c(23, 18, 12)/ lv$sum_expected_errors
```

double check with mokken package:

```{r unidim mokken, cache = T}
d_numeric <- apply(d, 2, as.numeric)
d_numeric <- d_numeric[, 2:6]
mokken::coefH(d_numeric)
```

Explain violations, recalculate H:

```{r unidim explain viol}
d_cp <- d
d_cp[89, 2+1] <- TRUE
d_cp[30, 1+1] <- TRUE
d_cp[36, 3+1] <- TRUE
loevenize(as.matrix(d_cp[,2:6]))$h
d_cp[41, 5+1] <- FALSE
d_cp[117, 5+1] <- FALSE
loevenize(as.matrix(d_cp[,2:6]))$h
```

### FA

```{r emp fa}
d_num <- apply(d[, c(-1, -7)], 2, as.numeric)
fa1 <- factanal(d_num, 1)
fa2 <- factanal(d_num, 2)

tab <- cbind(unclass(loadings(fa1)), unclass(loadings(fa2)))
print(
      xtable::xtable(tab, caption = "Factor analysis",
                     label = "tab:fa2", digits = 3),
      booktabs = TRUE,
      file = "tables/fa2.tex"
)
tab
```

### plot

```{r emp plot}
tab <- round(cor(d[, -c(1, 7)]), 2)

# max corr, when H for item 5 is 1
round(cor(d[-c(41, 117), -c(1, 7)]), 2)
loevenize(as.matrix(d[-c(41, 117), -c(1, 7)]))

a <- tril(lv$h_matrix, -1) # strict lower triangular matrix (omit diagonals)
b <- triu(tab, 1) # strict upper triangular matrix
c <- a + b
diag(c) <- NA

pdf("plots/itempairs.pdf", width = 7, height = 7)
plot(as.matrix(c), fmt.cell='%.2f', main = "", key = NULL,
xlab = "Item", ylab = "Item", col = sapply(seq(1, 0, -0.1), gray, alpha = 0.5))
dev.off()

plot(as.matrix(c), fmt.cell='%.2f', main = "", key = NULL,
xlab = "Item", ylab = "Item", col = sapply(seq(1, 0, -0.1), gray, alpha = 0.5))
```

